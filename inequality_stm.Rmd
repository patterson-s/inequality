---
title: "Inequality_Topic_Modelling"
author: "Scott Patterson"
date: '2020-02-24'
output: 
  md_document:
    variant: markdown_github
---

# Library

```{r Library}
pacman::p_load(stm,
               dplyr,
               quanteda)

```


# Ingest

Since the speecehs are saved as individual .txt files, I use the `quanteda` approach to import the text. 
Output: `corpus_1`, raw text files with unordered covariate metadata. 

Citation: Mikhaylov, Slava; Baturo, Alexander; Dasandi, Niheer, 2017, "United Nations General Debate Corpus", doi:10.7910/DVN/0TJX8Y, Harvard Dataverse, V3

```{r Ingest Raw Text}

# Read using Quanteda ----
corpus_1 <- readtext::readtext("/Users/ScottPatterson/OneDrive - McGill University/patterson_pouliot/inequality/inequality/unga_speeches", docvarsfrom = c("filenames"), dvsep = "_")

```

# Pre-processing
This step removes stop words, numbers, punctuation, stems the words, converts everything to lowercase. Use the `textProcessor` function. 
Output: corpus_2

```{r Pre-processing}
# Specify metadata from corpus ----
corpus_1_meta <- data.frame(corpus_1[,c(1,3:5)])

# textProcessor ----
corpus_2 <- textProcessor(documents = corpus_1$text,metadata = corpus_1_meta)


```

# Remove Infrequent Words 

`plotRemoved`
Removing infrequently used words. This function will allow us to see how many words would be removed at different threshholds. 

```{r Plot Removed Word thresholds}
# plotRemoved: test different thresholds for infrequent word removal ----

plotRemoved(corpus_2$documents, lower.thresh = seq(1,200, by = 25))

```

None of the documents are dropped at the 200 word threshhold. I can try to specify different models at different levels of sensitivity. The sharpest acceleration occurs between 0 - 25, gradually tapering off around 50 and eventually flattening out. 

Removing too many words may exclude important but infrequently appearing key words. Removing too few words will XXXX

Start with a lower threshold, later specifications at higher thresholds. 

`prepDocuments`
lower.thresh = 15
Output: corpus_3

```{r Remove Infrequent Words}
#prepDocuments ----

corpus_3 <- prepDocuments(corpus_2$documents, corpus_2$vocab, corpus_2$meta, lower.thresh = 15)

```


# Adding metadata covariates 

P5 = USA, FRA, CHN, GBR, RUS
  -The authors of the dataset code Soviet Union as Russia
```{r Covariate - P5}
# P5 ----
corpus_4 <- mutate(corpus_1, P5 = ifelse(docvar1 == "FRA", 1,
                                         ifelse(docvar1 == "USA", 1,
                                                ifelse(docvar1 == "GBR",1,
                                                       ifelse(docvar1 == "CHN",1,
                                                              ifelse(docvar1 == "RUS",1,0))))))


```


Nuclear Weapon States: NWS
P5 
India (1974)
Pakistan (1998)
North Korea (2006)
Israel (unknown)

```{r Covariate - NWS}
#NWS: P5 ----
corpus_4 <- mutate(corpus_4, NWS = ifelse(docvar1 == "FRA", 1,
                                         ifelse(docvar1 == "USA", 1,
                                                ifelse(docvar1 == "GBR",1,
                                                       ifelse(docvar1 == "CHN",1,
                                                              ifelse(docvar1 == "RUS",1,0))))))

# NWS: India ----
corpus_5 <- corpus_4

#corpus_5 %>%
  if(corpus_5$docvar1 == "IND" && corpus_5$docvar3 > 1973){corpus_5$NWS = 1}


```

# Preliminary Models 
```{r P5 }
# corpus_5 meta ----
corpus_5_meta <- data.frame(corpus_5[,c(1,3:6)])

# corpus_5 textProcessor ----
corpus_5_pro <- textProcessor(documents = corpus_5$text,metadata = corpus_5_meta)

# corpus_5 @ 5tokens prepDocuments ----
corpus_5_prep <- prepDocuments(corpus_5_pro$documents, corpus_5_pro$vocab, corpus_5_pro$meta, lower.thresh = 5)

# Estimate STM ----

prev_1 <- stm(documents = corpus_5_prep$documents, 
              vocab = corpus_5_prep$vocab, 
              K = 18, 
              prevalence = ~P5, 
              data = corpus_5_prep$meta, 
              init.type = "Spectral")

```


# Preliminary Analysis 

```{r}

# Base topic names ----
topicNames_18 <-c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7", "Topic 8", "Topic 9", "Topic 10", "Topic 11", "Topic 12", "Topic 13", "Topic 14", "Topic 15", "Topic 16", "Topic 17", "Topic 18")


```


# Label Topics 
- Go back through and filter out country names

- The words are displayed according to 4 metrics. Each represents a different mathematical weighting scheme for assigning words to topics

- Highest Prob: word frequency
- FREX: word frequency weigted w/ topic exclusivity 
- LIFT: another form of weighting; gives higher probability to words that don't appear in other topics 
- SCORE: similar to LIFT, but on log scale 


```{r}
labelTopics(prev_1, n = 20)

```


# Proportions
```{r Topical Proportions}
# Topical Proportions ----

proportions_prelim <- plot(prev_1, type = "summary", custom.labels = "", topic.names = topicNames_18, par(col="grey40", lwd=5))



```


